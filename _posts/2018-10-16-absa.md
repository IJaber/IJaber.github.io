---
title: "An Aspect-Based Sentiment Analysis of Customer Reviews"
date: 2018-10-16
---
## Project Aim
In this project, we proposed a novel approach to Aspect-Based Sentiment Analysis (ASBA) that is capable of accurately retrieving customer sentiments regarding specific aspects through analysing customer reviews. An ABSA is a technique that attempts to discover the most important aspects of a textual document and classify the sentiment polarity of the discovered aspects. Numerous ABSA methods have been proposed in the past, however, the majority of the models proposed were not scalable, and were mainly domain specific. The approach needs to be robust and versatile with the ability to perform across domains and languages, this is because customer reviews are being produced for a variety of products and services. ASBA is generally composed of two tasks, Aspect Detection, and Sentiment Analysis [Schouten and Frasincar, 2016]. Aspect Detection is the process of detecting aspects of an entity in a textual document. There are two main approaches to Aspect Detection – supervised and unsupervised. Sentiment Analysis captures the opinions and attitudes conveyed in text [Liu and Zhang, 2012].
[Project](/files/MScProject.pdf)
## NOA-LDA
By examining relevant literature, it was determined that previous Aspect Detection methods were lacking in either coherence or versatility. Thus, we proposed a Noun Only Approach (NOA) to the topic modelling technique Latent Dirichlet Allocation (NOA-LDA) for Aspect Detection. We showed through our testing that a NOA-LDA system is a superior method compared with a raw corpus LDA for Aspect Detection; it produced more accurate and coherent aspects. This was demonstrated with two examples: Hotel reviews, and Headphone reviews. Where both examples had considerably greater coherence with a NOA-LDA system than LDA with all POS. This confirms the work by Hu and Liu (2004) whose Aspect Detection approach found frequently occurring nouns and noun phrases, due to their assumption that vocabulary tends to converge when various aspects of a product are discussed. Our approach successfully extended upon the work by Titov and McDonald (2008), and Lin and He (2009) who used topic modelling to discover aspects. We managed to separate aspect words from opinion words through the NOA-LDA, whereas previous methods included both opinion words and aspect words in their approach, resulting in the topic model not being very accurate.  The NOA-LDA system was also significantly more computationally efficient. In terms of the scalability, run time for the NOA-LDA system was significantly faster than with a raw LDA. This was also demonstrated in both examples, the Hotel reviews performed approximately twice as fast with the NOA-LDA system, and the Headphone reviews performed approximately 15 times faster. The NOA-LDA system was also capable of performing across various domains. We showed this by selecting two examples from different domains.
### NOA preprocessing approach
Adequate pre-processing is necessary to ensure the LDA model results in coherent aspects. The Figure below gives an outline of the NOA-LDA pre-processing method for Aspect Detection.
![NOA](/images/NOApre.jpg)
```r
library(RTextTools)
library(topicmodels)
library(dplyr)
library(tm)
library(lexRankr)
# Import text data
reviews <- reviews_df
# Sentence parse and Isolate text
reviews <- sentenceParse(reviews$comments)
reviews_text <- reviews$sentence
# average length of sentence
mean(sapply(reviews$sentence,function(x)length(unlist(gregexpr(" ",x)))+1))
# Make a Source object
review_source <- VectorSource(reviews_text)
# Make a corpus
review_corpus <- Corpus(review_source)
# Print out
review_corpus
# cleaning
review_corpus <- review_corpus %>%
  tm_map(content_transformer(tolower)) %>%
  tm_map(removePunctuation) %>%
  tm_map(stripWhitespace) %>%
  tm_map(removeNumbers) %>%
  tm_map(removeWords, stopwords("english"))
# tokenize the corpus
review_corpus <- lapply(review_corpus, scan_tokenizer)
# concatenate tokens by document, create data frame
Reviews <- data.frame(text = sapply(review_corpus, paste, collapse = " "), stringsAsFactors = FALSE)
# Remove sentences with less than three words
Reviews <- as.data.frame(Reviews[sapply(strsplit(as.character(Reviews$text)," "),length)>2,])
colnames(Reviews)[colnames(Reviews) == 'Reviews[sapply(strsplit(as.character(Reviews$text), " "), length) > 2, ]'] <- 'text'
# Add sentence ID
Reviews$ID <- seq.int(nrow(Reviews))
str(Reviews)
Reviews$text <- as.character(Reviews$text)
save(Reviews, file = "Reviews.Rda")
# Annotate POS with udpipe
library(udpipe)
udmodel <- udpipe_download_model(language = "english")
udmodel <- udpipe_load_model(file = 'english-ud-2.0-170801.udpipe')
x <- udpipe_annotate(udmodel, x = Reviews$text, doc_id = Reviews$ID)
x <- as.data.frame(x)
str(x)
x$topic_level_id <- unique_identifier(x, fields = c("doc_id"))
save(x, file = "x.Rda")
# Get a data.frame with 1 row per id/lemma and extract only nouns
dtf <- subset(x, upos %in% c("NOUN"))
dtf <- document_term_frequencies(dtf, document = "topic_level_id", term = "lemma")
head(dtf)
# Create a document/term/matrix for building a topic model
dtm <- document_term_matrix(x = dtf)
# Remove words which do not occur that much
dtm_clean <- dtm_remove_lowfreq(dtm, minfreq = 50)
```
### LDA approach
For the LDA we use a standard implementation method. The figure below gives an outline of the LDA method used for Aspect Detection.
![lda](/images/lda.jpg)
```r
library(RTextTools)
library(topicmodels)
library(lexRankr)
# find k
best.model <- lapply(seq(2,100, by=1), function(k){LDA(dtm_clean[21:30,], k)})
best.model.logLik <- as.data.frame(as.matrix(lapply(best.model, logLik)))
best.model.logLik.df <- data.frame(topics=c(2:100), LL=as.numeric(as.matrix(best.model.logLik)))
library(ggplot2)
ggplot(best.model.logLik.df, aes(x=topics, y=LL)) +
  xlab("Number of topics") + ylab("Log likelihood of the model") +
  geom_line() +
  theme_bw() +
  scale_x_continuous(breaks = round(seq(min(best.model.logLik.df$topics), max(best.model.logLik.df$topics), by = 10),1))
best.model.logLik.df[which.max(best.model.logLik.df$LL),]
# run lda
system.time(lda <- LDA(dtm_clean, k = 4, method = "Gibbs",
           control = list(nstart = 3, burnin = 4000, iter = 4000, thin = 500, best = TRUE, seed = 1:3)))
noun_terms <- predict(lda, type = "terms", min_posterior= 0.05, min_terms = 5)
noun_terms
noun_topics <- as.matrix(topics(lda))
save(noun_topics, file = "noun_topics.rda")
```

## PLSS
In this project, we also presented an intuitive system for Sentiment Analysis. We presented the Pragmatic Lexicon Scoring System (PLSS) for Sentiment Analysis that successfully assigned ratings to aspects through a Lexicon-based approach. Our approach employed a customer review orientated Lexicon built to resolve the flaws of previous methods which did not consider how customers used opinionated text to assign ratings. For instance, in the AFINN lexicon, the reviewer needs to use words such as “breathtaking” and “outstanding” in order to allocate 5 stars. This sort of vocabulary is common amongst professional critics, but not amongst the majority of customer reviews. We found that extracting adjectives through POS tagging from customer review titles could allow us to assign a fair and realistic polarity rating to opinionated words. Our intuition behind this is the assumption that adjectives used in review titles typically convey the overall customer sentiment towards a product or service, allowing us to retrieve a sentiment score for each adjective.
### PLSS construction
Our system uses a large collection of pre-labelled reviews to extract adjectives and their associated ratings. The adjectives will be used to build a seed lexicon list which will be expanded using synonyms. An outline of our PLSS construction can be seen in the figure below.
![PLSS](/images/PLSS.jpg)
```r
library(tm) # text mining
library(dplyr)
library(udpipe)
# import data and clean
load("collection_reviews.rda")
names(collection_reviews) <- c("stars", "comments")
# change stars to factor and add document id
collection_reviews$stars <- as.factor(collection_reviews$stars)
collection_reviews$document <- seq.int(nrow(collection_reviews))
# a vector source interprets each element of the vector as a document
sourceData <- VectorSource(collection_reviews$comments)
# create the corpus
corpus <- Corpus(sourceData)
# preprocess/clean the training corpus
corpus <- corpus %>%
  tm_map(content_transformer(tolower)) %>%
  tm_map(removeNumbers) %>%
  tm_map(removePunctuation)
# create term document matrix (tdm)
tdm <- TermDocumentMatrix(corpus)
# coverting the data and attaching star ratings
library(tidytext)
tdm <- tidy(tdm)
tdm$document <- as.integer(tdm$document)
collection_reviews$comments <- NULL
tdm <- inner_join(tdm, collection_reviews, by="document")
# save tdm for later use
save(tdm, file = "tdm.rda")
# annotate
udmodel <- udpipe_download_model(language = "english")
udmodel <- udpipe_load_model(file = 'english-ud-2.0-170801.udpipe')
x <- udpipe_annotate(udmodel, x = tdm$term, doc_id = tdm$document)
x <- as.data.frame(x)
save(x, file = "xpos.rda")
# subset for adjectives
x$id <- unique_identifier(x, fields = c("doc_id"))
dtf <- subset(x, upos %in% c("ADJ"))
dtf <- document_term_frequencies(dtf, document = "id", term = "lemma")
# clean and join with star rating
# first join with x to retrieve document number
x[2:14] <- NULL
x <- x %>%
  distinct(doc_id,id, .keep_all = TRUE)
names(x) <- c("document", "doc_id")
dtf <- inner_join(dtf, x, by = "doc_id")
dtf$document <- as.integer(dtf$document)
collection_reviews$comments <- NULL
dtf <- inner_join(dtf, collection_reviews, by="document")
dtf$freq <- NULL
dtf$doc_id <- NULL
# create lexicon
lexicon <- dtf
lexicon$stars <- as.integer(lexicon$stars)
lexicon <- lexicon  %>%
  group_by(term) %>%
  dplyr::summarise(stars = mean(stars, na.rm = TRUE))
colnames(lexicon)[colnames(lexicon)=="term"] <- "word"
save(lexicon, file = 'lexicon.rda')
```
### Sentiment Classification using PLSS
Using the PLSS constructed Lexicon list, the next step is to assign a sentiment polarity rating to aspect labelled sentences. An outline of our Sentiment Classification approach using our Lexicon list is shown in the figure below.
![SentimentClassification](/images/SC.jpg)
```r
library(dplyr)
library(RTextTools)
library(tidytext)
load("x.Rda")
load("noun_topics.Rda")
# clean udpipe annotated df and remove dupicated rows
x[5:14] <- list(NULL)
x <- x %>%
  distinct(doc_id, .keep_all = TRUE)
x <- x[4:5]
# join with topics
Topics <- merge(x = x, y = noun_topics ,
                by.x = "topic_level_id",by.y = "X1",
                all.x = TRUE)
# remove missing rows
Topics <- na.omit(Topics)
# remove uneeded columns and rename
Topics[1] <- NULL
colnames(Topics)[colnames(Topics)=="V1"] <- "topic.number"
load("lexicon.rda")
# sentiment analysis
# unnest tokens
data.words <- Topics %>%
  select(sentence, topic.number, Topics) %>%
  unnest_tokens(word, sentence)
# lexicon topic
POS.sentiment <- data.words %>%
  inner_join(lexicon, by = "word") %>%
  group_by(topic.number, Topics)
POS.sentiment <- data.words %>%
  inner_join(lexicon, by = "word") %>%
  group_by(topic.number, Topics) %>%
  summarize(Rating = mean(stars))
# find the average rating per aspect
POS.sentiment
mean(POS.sentiment$Rating)
# save file
write.csv(POS.sentiment, file = "POS_sentiment.csv")
```
